import streamlit as st
import pandas as pd
import re
from datetime import datetime
from io import BytesIO
from typing import List, Dict, Tuple

# --- YOUR ORIGINAL SOPHISTICATED VALIDATOR CLASS (UNCHANGED) ---
class EnhancedTraditionalValidator:
    def __init__(self):
        self.simplified_to_traditional = {
            'ä¸‡': 'è¬', 'äº¿': 'å„„', 'è´°': 'è²³', 'ä¸¤': 'å…©', 'é™†': 'é™¸', 'å¸': 'å¹£', 'é“¶': 'éŠ€',
            'é’±': 'éŒ¢', 'è´µ': 'è²´', 'å®': 'å¯¶', 'è´¢': 'è²¡', 'è´§': 'è²¨', 'è´­': 'è³¼', 'è´¹': 'è²»',
            'ä»·': 'åƒ¹', 'ä¹°': 'è²·', 'å–': 'è³£', 'å€º': 'å‚µ', 'è´·': 'è²¸', 'è´¦': 'è³¬', 'å‚¨': 'å„²',
            'è¿˜': 'é‚„', 'ç»“': 'çµ', 'ä½™': 'é¤˜', 'é¢': 'é¡', 'æˆ·': 'æˆ¶', 'å¤´': 'é ­', 'èµ„': 'è³‡',
            'é™©': 'éšª', 'æ‹…': 'æ“”', 'è´£': 'è²¬', 'æƒ': 'æ¬Š', 'ç¨Ž': 'ç¨…', 'å›½': 'åœ‹', 'åŽ': 'è¯',
            'äº§': 'ç”¢', 'ä¸š': 'æ¥­', 'å¹¿': 'å»£', 'æ¹¾': 'ç£', 'å²›': 'å³¶', 'å°': 'è‡º', 'å²­': 'å¶º',
            'å³°': 'å³¯', 'ä¸œ': 'æ±', 'å†…': 'å…§', 'åŒº': 'å€', 'åŽ¿': 'ç¸£', 'æ—¶': 'æ™‚', 'é—´': 'é–“',
            'å‘¨': 'é€±', 'é’Ÿ': 'é˜', 'åŽ†': 'æ­·', 'çºª': 'ç´€', 'å¼€': 'é–‹', 'å…³': 'é—œ', 'é—¨': 'é–€',
            'è½¦': 'è»Š', 'ç”µ': 'é›»', 'è¯': 'è©±', 'å‘': 'ç™¼', 'è¯': 'è­‰', 'ä¹¦': 'æ›¸', 'å•': 'å–®',
            'æ®': 'æ“š', 'æ¡': 'æ¢', 'é¡¹': 'é …', 'å½•': 'éŒ„', 'å†Œ': 'å†Š', 'è®¾': 'è¨­', 'åŠž': 'è¾¦',
            'åŠ¡': 'å‹™', 'æ€»': 'ç¸½', 'ç»': 'ç¶“', 'è¥': 'ç‡Ÿ', 'å¤„': 'è™•', 'é•¿': 'é•·', 'å‘˜': 'å“¡',
            'å¹²': 'å¹¹', 'çº§': 'ç´š', 'è¿‡': 'éŽ', 'è¿™': 'é€™', 'ä»¬': 'å€‘', 'ä¸ª': 'å€‹', 'ä¸º': 'ç‚º',
            'ä»Ž': 'å¾ž', 'æ¥': 'ä¾†', 'å¯¹': 'å°', 'ä¼š': 'æœƒ', 'æ ·': 'æ¨£', 'ç§': 'ç¨®', 'çŽ°': 'ç¾',
            'å®ž': 'å¯¦', 'è®©': 'è®“', 'ç»™': 'çµ¦', 'ä¸Ž': 'èˆ‡', 'è™½': 'é›–', 'åŽ': 'å¾Œ', 'å­¦': 'å­¸',
            'å¸ˆ': 'å¸«', 'è¯¾': 'èª²', 'ç»„': 'çµ„', 'é˜Ÿ': 'éšŠ', 'å›¢': 'åœ˜', 'ç½‘': 'ç¶²', 'ç»œ': 'çµ¡',
            'é¡µ': 'é ', 'ç ': 'ç¢¼', 'å·': 'è™Ÿ', 'çº¿': 'ç·š', 'æœº': 'æ©Ÿ', 'å¤‡': 'å‚™', 'è£…': 'è£',
            'è¯´': 'èªª', 'è®²': 'è¬›', 'å¬': 'è½', 'è¯»': 'è®€', 'å†™': 'å¯«', 'è®°': 'è¨˜', 'å¿†': 'æ†¶',
            'è™‘': 'æ…®', 'å†³': 'æ±º', 'é€‰': 'é¸', 'æ‹©': 'æ“‡', 'èˆ': 'æ¨', 'å¼ƒ': 'æ£„', 'èŽ·': 'ç²',
            'æŠ¤': 'è­·', 'æŠ¥': 'å ±', 'è¡¨': 'éŒ¶', 'åˆ¶': 'è£½', 'å¤': 'å¾©', 'çˆ±': 'æ„›', 'æ¬¢': 'æ­¡',
            'ä¹': 'æ¨‚', 'å¿§': 'æ†‚', 'æ»¡': 'æ»¿', 'å‡€': 'æ·¨', 'è„': 'é«’', 'æ—§': 'èˆŠ', 'è½»': 'è¼•',
            'å®½': 'å¯¬', 'æµ…': 'æ·º', 'è¿œ': 'é ', 'å¤Ÿ': 'å¤ ', 'ç´§': 'ç·Š', 'æ¾': 'é¬†', 'å': 'å£ž',
            'ä¸‘': 'é†œ', 'å¼º': 'å¼·', 'é’¢': 'é‹¼', 'é“': 'éµ', 'é“œ': 'éŠ…', 'é“': 'é‹', 'é”¡': 'éŒ«',
            'çº¸': 'ç´™', 'ä¸': 'çµ²', 'ç»³': 'ç¹©', 'å¸¦': 'å¸¶', 'çº¢': 'ç´…', 'ç»¿': 'ç¶ ', 'è“': 'è—',
            'é»„': 'é»ƒ', 'é©¬': 'é¦¬', 'é¸Ÿ': 'é³¥', 'é±¼': 'é­š', 'é¾Ÿ': 'é¾œ', 'è™«': 'èŸ²', 'ç‹®': 'ç…',
            'çŒ«': 'è²“', 'çŒª': 'è±¬', 'æ ‘': 'æ¨¹', 'å¶': 'è‘‰', 'éº¦': 'éº¥', 'è„¸': 'è‡‰', 'è„š': 'è…³',
            'è„‘': 'è…¦', 'è£¤': 'è¤²', 'è¢œ': 'è¥ª', 'é¥­': 'é£¯', 'é¢': 'éºµ', 'æ±¤': 'æ¹¯', 'é¸¡': 'é›ž',
            'è™¾': 'è¦', 'ç›': 'é¹½', 'é£ž': 'é£›', 'æ¥¼': 'æ¨“', 'å¢™': 'ç‰†', 'é¡¶': 'é ‚', 'å›­': 'åœ’',
            'ç¬”': 'ç­†', 'ç¯': 'ç‡ˆ', 'é£Ž': 'é¢¨', 'äº‘': 'é›²', 'çƒ­': 'ç†±', 'é‡Œ': 'è£¡', 'è¾¹': 'é‚Š',
            'ç»†': 'ç´°', 'å„¿': 'å…’', 'å­™': 'å­«', 'çˆ·': 'çˆº', 'å†œ': 'è¾²', 'åŒ»': 'é†«', 'æ¿': 'é—†',
            'è§„': 'è¦', 'åˆ™': 'å‰‡', 'å†›': 'è»', 'æˆ˜': 'æˆ°', 'æ–—': 'é¬¥', 'èƒœ': 'å‹', 'è´¥': 'æ•—',
            'æ•Œ': 'æ•µ', 'åº™': 'å»Ÿ', 'ç¥·': 'ç¦±', 'å£°': 'è²', 'æ•°': 'æ•¸', 'ç”»': 'ç•«', 'æˆ': 'æˆ²',
            'å‰§': 'åŠ‡', 'è¯—': 'è©©', 'è¯': 'è©ž', 'è¯': 'è—¥', 'ä¼¤': 'å‚·', 'ç–—': 'ç™‚', 'åŽ‚': 'å» ',
            'åœº': 'å ´', 'åº†': 'æ…¶', 'ç¤¼': 'ç¦®', 'å›¾': 'åœ–', 'çŠ¶': 'ç‹€', 'æ ‡': 'æ¨™', 'å¿—': 'èªŒ',
            'ç±»': 'é¡ž', 'è´¨': 'è³ª', 'è®¡': 'è¨ˆ', 'ç´¯': 'ç´¯', 'ç§¯': 'ç©', 'å¹¶': 'ä½µ', 'è”': 'è¯',
            'å¼‚': 'ç•°', 'åˆ«': 'åˆ¥', 'è·': 'è·', 'ç¦»': 'é›¢', 'å‡': 'æ¸›', 'è¾ƒ': 'è¼ƒ', 'äºŽ': 'æ–¼',
            'å®¾': 'è³“', 'æ»¨': 'æ¿±', 'ç¼¤': 'ç¹½', 'é¢‘': 'é »', 'é¬“': 'é¬¢', 'é«Œ': 'é«•', 'è†‘': 'è‡',
            'æ§Ÿ': 'æª³', 'æ‘ˆ': 'æ“¯', 'å‚§': 'å„', 'æ®¡': 'æ®¯', 'é•”': 'é‘Œ', 'é¥¼': 'é¤…', 'ç¦€': 'ç¨Ÿ',
            'æ‹¨': 'æ’¥', 'å‰¥': 'å‰', 'é©³': 'é§', 'é’¹': 'éˆ¸', 'é•ˆ': 'éŽ›', 'é“‚': 'é‰‘', 'é’µ': 'ç¼½',
            'é¥½': 'é¤‘', 'è¡¥': 'è£œ', 'å¸ƒ': 'ä½ˆ', 'å®ª': 'æ†²', 'å®¡': 'å¯©', 'è¯‘': 'è­¯', 'è®®': 'è­°',
            'è®¤': 'èª', 'è¯†': 'è­˜', 'è¯•': 'è©¦', 'è¯¯': 'èª¤', 'è®¿': 'è¨ª', 'è¯„': 'è©•', 'è°ƒ': 'èª¿',
            'æ£€': 'æª¢', 'éªŒ': 'é©—', 'æµ‹': 'æ¸¬', 'è½¯': 'è»Ÿ', 'æ˜¾': 'é¡¯', 'è¾“': 'è¼¸', 'æž„': 'æ§‹',
            'è´¸': 'è²¿', 'é”€': 'éŠ·', 'è®¢': 'è¨‚', 'è¿': 'é‹', 'é€’': 'éž', 'é‚®': 'éƒµ', 'ä¼—': 'çœ¾',
            'ä¼™': 'å¤¥', 'äº²': 'è¦ª', 'ç§°': 'ç¨±', 'å”¤': 'å–š', 'é•‡': 'éŽ®', 'åº„': 'èŽŠ', 'æ¡¥': 'æ©‹',
            'çŽ¯': 'ç’°', 'å°˜': 'å¡µ', 'é›¾': 'éœ§', 'ä¸¾': 'èˆ‰', 'æŠ›': 'æ‹‹', 'æ¸¸': 'éŠ', 'å“': 'åš‡',
            'æ°”': 'æ°£', 'æ¼': 'æƒ±', 'çƒ¦': 'ç…©', 'æ¡£': 'æª”', 'è½½': 'è¼‰', 'ä¼ ': 'å‚³', 'è¾¾': 'é”',
            'é¢†': 'é ˜', 'èµ ': 'è´ˆ', 'çŒ®': 'ç»', 'æ®': 'æ“š', 'å‡­': 'æ†‘', 'æ‰§': 'åŸ·', 'ç­¾': 'ç°½',
            'ç›–': 'è“‹', 'æŸœ': 'æ«ƒ'
        }
        self.simplified_chars = set(self.simplified_to_traditional.keys())

    def find_simplified_characters(self, text: str) -> Dict[str, List[str]]:
        if not text or not isinstance(text, str):
            return {'simplified_found': [], 'suggestions': []}
        simplified_found = []
        suggestions = []
        for char in text:
            if char in self.simplified_chars and char not in simplified_found:
                simplified_found.append(char)
                suggestions.append(f"{char} â†’ {self.simplified_to_traditional[char]}")
        return {'simplified_found': simplified_found, 'suggestions': suggestions}

    def get_text_status(self, text: str) -> Tuple[str, str]:
        if not text or not isinstance(text, str):
            return "EMPTY", "No text to check"
        simplified_count = len(self.find_simplified_characters(text)['simplified_found'])
        if simplified_count == 0:
            return "TRADITIONAL", "All characters are traditional"
        else:
            return "HAS_SIMPLIFIED", f"Found {simplified_count} simplified character(s)"

    def analyze_dataframe(self, df: pd.DataFrame, chinese_columns: List[str]):
        """Analyze Chinese text for simplified characters with the enhanced database."""
        results, stats = [], {'total_rows': 0, 'traditional_only': 0, 'has_simplified': 0, 'empty_cells': 0, 'total_simplified_chars': 0}
        inventory_col = df.columns[0] if len(df.columns) > 0 else None
        
        for index, row in df.iterrows():
            for col_name in chinese_columns:
                if col_name not in df.columns: continue
                text = row[col_name]
                stats['total_rows'] += 1
                if pd.isna(text) or text == '':
                    stats['empty_cells'] += 1
                    continue
                text = str(text)
                status, _ = self.get_text_status(text)
                if status == "HAS_SIMPLIFIED":
                    simplified_analysis = self.find_simplified_characters(text)
                    stats['has_simplified'] += 1
                    stats['total_simplified_chars'] += len(simplified_analysis['simplified_found'])
                    inventory_value = row[inventory_col] if inventory_col else f"Row {index + 2}"
                    results.append({
                        'inventory': inventory_value, 'row_number': index + 2, 'column': col_name,
                        'text': text, 'simplified_chars': simplified_analysis['simplified_found'],
                        'suggestions': simplified_analysis['suggestions']
                    })
                else:
                    stats['traditional_only'] += 1
        return results, stats

# --- STREAMLIT USER INTERFACE ---
st.set_page_config(page_title="Traditional Chinese Validator", layout="wide")
st.title("ðŸ‡¨ðŸ‡³ Enhanced Traditional Chinese Character Validator")
st.markdown("ðŸš€ **Enhanced with 500+ character database!** This tool validates Excel files to ensure all Chinese text is in traditional characters.")

# Initialize the validator
validator = EnhancedTraditionalValidator()
st.sidebar.info(f"Database loaded with **{len(validator.simplified_to_traditional)}** character mappings.")

# --- File Upload and Column Selection ---
st.header("1. Upload Your Excel File")
uploaded_file = st.file_uploader("Select an Excel file (.xlsx or .xls)", type=["xlsx", "xls"])

if uploaded_file:
    try:
        df = pd.read_excel(uploaded_file, nrows=0) # Read only headers for speed
        columns = list(df.columns)
        st.header("2. Select Columns to Validate")
        
        # Auto-detect Chinese columns as a default
        sample_df = pd.read_excel(uploaded_file, nrows=5)
        default_cols = [col for col in columns if sample_df[col].astype(str).str.contains(r'[\u4e00-\u9fff]').any()]
        
        selected_columns = st.multiselect(
            "Select all columns containing Chinese text that need to be validated:",
            options=columns,
            default=default_cols,
            help="The app attempts to auto-select columns with Chinese characters. You can add or remove columns from the selection."
        )

        st.header("3. Start Validation")
        if st.button("ðŸš€ Analyze Now"):
            if not selected_columns:
                st.warning("Please select at least one column to analyze.")
            else:
                with st.spinner("Processing all rows... This may take a moment."):
                    full_df = pd.read_excel(uploaded_file)
                    results, stats = validator.analyze_dataframe(full_df, selected_columns)

                    st.header("ðŸ“Š Validation Results")
                    
                    # --- Summary Statistics ---
                    st.subheader("ðŸ“ˆ Summary Statistics")
                    if (stats['total_rows'] - stats['empty_cells']) > 0:
                        compliance = (stats['traditional_only'] / (stats['total_rows'] - stats['empty_cells'])) * 100
                    else:
                        compliance = 100
                    
                    c1, c2, c3, c4 = st.columns(4)
                    c1.metric("Compliance", f"{compliance:.1f}%")
                    c2.metric("Cells with Simplified", stats['has_simplified'])
                    c3.metric("Total Simplified Chars", stats['total_simplified_chars'])
                    c4.metric("Total Cells Processed", stats['total_rows'])
                    
                    # --- Detailed Report ---
                    if results:
                        st.subheader("ðŸš¨ Entries with Simplified Characters")
                        
                        # Create a clean DataFrame for display and download
                        output_data = [{
                            'Inventory #': r['inventory'], 'Row #': r['row_number'], 'Column': r['column'],
                            'Original Text': r['text'], 'Simplified Found': ', '.join(r['simplified_chars']),
                            'Suggestions': ' | '.join(r['suggestions'])
                        } for r in results]
                        output_df = pd.DataFrame(output_data)
                        
                        st.dataframe(output_df)
                        
                        # Prepare Excel file for download
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            output_df.to_excel(writer, sheet_name='Validation_Report', index=False)
                        output.seek(0)
                        
                        timestamp = datetime.now().strftime("%Y-%m-%d_%H%M")
                        st.download_button(
                            label="ðŸ“„ Download Full Report (.xlsx)",
                            data=output,
                            file_name=f"Traditional_Validation_Report_{timestamp}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                        
                        # --- Summary of all unique issues ---
                        st.subheader("ðŸ“‹ Summary of All Unique Issues Found")
                        unique_issues = {}
                        for r in results:
                            for suggestion in r['suggestions']:
                                s_char, t_char = suggestion.split(' â†’ ')
                                unique_issues[s_char] = t_char
                        
                        summary_text = " | ".join([f"{s}â†’{t}" for s, t in sorted(unique_issues.items())])
                        st.text_area("All unique simplified characters found and their traditional counterparts:", summary_text, height=150)
                        
                    else:
                        st.success("ðŸŽ‰ **Excellent! No simplified characters were found.** All selected columns are compliant.")
    
    except Exception as e:
        st.error(f"An error occurred while processing the file: {e}")
else:
    st.info("Please upload an Excel file to begin the validation process.")
